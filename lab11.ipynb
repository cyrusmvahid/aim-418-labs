{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIV='tanh'\n",
    "L1_UNITS = 60\n",
    "L2_UNITS = 20\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "WD = 0\n",
    "MOMENTUM = .9\n",
    "CTX = mx.gpu()\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(l1u=50, l2u=20, act='tanh', num_classes=10):\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(gluon.nn.Dense(units=l1u, activation=act))\n",
    "        net.add(gluon.nn.Dense(units=l2u, activation=act))\n",
    "        net.add(gluon.nn.Dense(num_classes))\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    return net, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Dense(None -> 50, Activation(tanh))\n",
       "   (1): Dense(None -> 20, Activation(tanh))\n",
       "   (2): Dense(None -> 10, linear)\n",
       " ), SoftmaxCrossEntropyLoss(batch_axis=0, w=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, loss = MLP()\n",
    "(net, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    return (data.astype('float32')/255, label.astype('float32'))\n",
    "train_dataset = gluon.data.vision.MNIST(train=True, transform=transform)\n",
    "test_dataset = gluon.data.vision.MNIST(train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(dataset=train_dataset, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   shuffle=True)\n",
    "\n",
    "test_data = gluon.data.DataLoader(dataset=test_dataset, \n",
    "                                  batch_size=BATCH_SIZE, \n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(mx.init.Xavier(magnitude=2.24),\n",
    "               ctx=CTX, \n",
    "               force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(params=net.collect_params(), \n",
    "                        optimizer='sgd', \n",
    "                        optimizer_params={'learning_rate': LR, 'momentum':MOMENTUM, 'wd':WD})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, network, ctx, metrics=[mx.metric.Accuracy(), mx.metric.RMSE()]):\n",
    "    metric = mx.metric.CompositeEvalMetric(metrics=metrics)\n",
    "    metric.reset()\n",
    "    for i, (d,l) in enumerate(dataloader):\n",
    "        d  = d.as_in_context(ctx)\n",
    "        l = l.as_in_context(ctx)\n",
    "        predictions = network(d)\n",
    "        metric.update(preds=predictions, labels=l)\n",
    "    return metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, network, loss_fn , trainer, ctx, epochs=10):\n",
    "    for e in range(epochs):\n",
    "        print(\"EPOCH#: {}\".format(e))\n",
    "        epoch_loss = 0\n",
    "        for i, (d, label) in enumerate(dataloader):\n",
    "            d = d.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                predictions = network(d)\n",
    "                loss = loss_fn(predictions, label)\n",
    "            loss.backward()\n",
    "            trainer.step(d.shape[0])\n",
    "            test_val = evaluate(dataloader=test_data, network=network, ctx=ctx)\n",
    "            train_val = evaluate(dataloader=train_data, network=network, ctx=ctx)\n",
    "            if ( i % 100 ) == 0:\n",
    "                print(\"Minibactch#: {}: mean loss: {}\".format(i, loss.mean().asscalar()))\n",
    "                epoch_loss += loss.mean().asscalar()\n",
    "                print(\"test metrics: {}\".format(test_val.get_name_value()))\n",
    "                print(\"train metrics: {}\".format(train_val.get_name_value()))\n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH#: 0\n",
      "Minibactch#: 0: mean loss: 0.25654923915863037\n",
      "test metrics: [('accuracy', 0.9180166666666667), ('rmse', 5.787024036907693)]\n",
      "train metrics: [('accuracy', 0.9180166666666667), ('rmse', 5.787024036907693)]\n"
     ]
    }
   ],
   "source": [
    "train(train_data, net, loss, trainer, CTX, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
