{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIV='tanh'\n",
    "L1_UNITS = 60\n",
    "L2_UNITS = 20\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "WD = 0\n",
    "MOMENTUM = .9\n",
    "CTX = mx.gpu()\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(l1u=50, l2u=20, act='tanh', num_classes=10):\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(gluon.nn.Dense(units=l1u, activation=act))\n",
    "        net.add(gluon.nn.Dense(units=l2u, activation=act))\n",
    "        net.add(gluon.nn.Dense(num_classes))\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    return net, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Dense(None -> 50, Activation(tanh))\n",
       "   (1): Dense(None -> 20, Activation(tanh))\n",
       "   (2): Dense(None -> 10, linear)\n",
       " ), SoftmaxCrossEntropyLoss(batch_axis=0, w=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, loss = MLP()\n",
    "(net, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    return (data.astype('float32')/255, label.astype('float32'))\n",
    "train_dataset = gluon.data.vision.MNIST(train=True, transform=transform)\n",
    "test_dataset = gluon.data.vision.MNIST(train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(dataset=train_dataset, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   shuffle=True)\n",
    "\n",
    "test_data = gluon.data.DataLoader(dataset=test_dataset, \n",
    "                                  batch_size=BATCH_SIZE, \n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(mx.init.Xavier(magnitude=2.24),\n",
    "               ctx=CTX, \n",
    "               force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(params=net.collect_params(), \n",
    "                        optimizer='sgd', \n",
    "                        optimizer_params={'learning_rate': LR, 'momentum':MOMENTUM, 'wd':WD})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, network, loss_fn , trainer, ctx, epochs=10):\n",
    "    for e in range(epochs):\n",
    "        print(\"EPOCH#: {}\".format(e))\n",
    "        epoch_loss = 0\n",
    "        for i, (d, label) in enumerate(dataloader):\n",
    "            d = d.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                predictions = network(d)\n",
    "                loss = loss_fn(predictions, label)\n",
    "            loss.backward()\n",
    "            trainer.step(d.shape[0])\n",
    "            if ( i % 100 ) == 0:\n",
    "                print(\"Minibactch#: {}: mean loss: {}\".format(i, loss.mean().asscalar()))\n",
    "                epoch_loss += loss.mean().asscalar()\n",
    "        print(\"EPOCH LOSS: {}\".format(epoch_loss/d.shape[0]))\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH#: 0\n",
      "Minibactch#: 0: mean loss: 2.332568407058716\n",
      "Minibactch#: 100: mean loss: 1.723408579826355\n",
      "Minibactch#: 200: mean loss: 1.3712990283966064\n",
      "Minibactch#: 300: mean loss: 1.1950805187225342\n",
      "Minibactch#: 400: mean loss: 1.0124510526657104\n",
      "Minibactch#: 500: mean loss: 0.9406935572624207\n",
      "Minibactch#: 600: mean loss: 0.7341489195823669\n",
      "Minibactch#: 700: mean loss: 0.9151694774627686\n",
      "Minibactch#: 800: mean loss: 0.6902312636375427\n",
      "Minibactch#: 900: mean loss: 0.7092996835708618\n",
      "EPOCH LOSS: 0.36326095275580883\n",
      "EPOCH#: 1\n",
      "Minibactch#: 0: mean loss: 0.653210461139679\n",
      "Minibactch#: 100: mean loss: 0.6352062821388245\n",
      "Minibactch#: 200: mean loss: 0.6736405491828918\n",
      "Minibactch#: 300: mean loss: 0.44345277547836304\n",
      "Minibactch#: 400: mean loss: 0.5761818885803223\n",
      "Minibactch#: 500: mean loss: 0.5809483528137207\n",
      "Minibactch#: 600: mean loss: 0.6157048344612122\n",
      "Minibactch#: 700: mean loss: 0.7161040306091309\n",
      "Minibactch#: 800: mean loss: 0.4491504728794098\n",
      "Minibactch#: 900: mean loss: 0.5066078901290894\n",
      "EPOCH LOSS: 0.1828189855441451\n",
      "EPOCH#: 2\n",
      "Minibactch#: 0: mean loss: 0.3197709023952484\n",
      "Minibactch#: 100: mean loss: 0.2967401444911957\n",
      "Minibactch#: 200: mean loss: 0.5298060178756714\n",
      "Minibactch#: 300: mean loss: 0.40186434984207153\n",
      "Minibactch#: 400: mean loss: 0.4053637385368347\n",
      "Minibactch#: 500: mean loss: 0.4168478846549988\n",
      "Minibactch#: 600: mean loss: 0.2531387209892273\n",
      "Minibactch#: 700: mean loss: 0.40265023708343506\n",
      "Minibactch#: 800: mean loss: 0.2520279586315155\n",
      "Minibactch#: 900: mean loss: 0.2775593101978302\n",
      "EPOCH LOSS: 0.11111778952181339\n",
      "EPOCH#: 3\n",
      "Minibactch#: 0: mean loss: 0.5476382970809937\n",
      "Minibactch#: 100: mean loss: 0.41452756524086\n",
      "Minibactch#: 200: mean loss: 0.4183008670806885\n",
      "Minibactch#: 300: mean loss: 0.34825199842453003\n",
      "Minibactch#: 400: mean loss: 0.26480183005332947\n",
      "Minibactch#: 500: mean loss: 0.3433637022972107\n",
      "Minibactch#: 600: mean loss: 0.2067965716123581\n",
      "Minibactch#: 700: mean loss: 0.5307329297065735\n",
      "Minibactch#: 800: mean loss: 0.24832695722579956\n",
      "Minibactch#: 900: mean loss: 0.32601022720336914\n",
      "EPOCH LOSS: 0.11402346706017852\n",
      "EPOCH#: 4\n",
      "Minibactch#: 0: mean loss: 0.3643266558647156\n",
      "Minibactch#: 100: mean loss: 0.461948424577713\n",
      "Minibactch#: 200: mean loss: 0.29021042585372925\n",
      "Minibactch#: 300: mean loss: 0.32596680521965027\n",
      "Minibactch#: 400: mean loss: 0.45141667127609253\n",
      "Minibactch#: 500: mean loss: 0.34175905585289\n",
      "Minibactch#: 600: mean loss: 0.44351819157600403\n",
      "Minibactch#: 700: mean loss: 0.323173850774765\n",
      "Minibactch#: 800: mean loss: 0.5367270112037659\n",
      "Minibactch#: 900: mean loss: 0.4362438917160034\n",
      "EPOCH LOSS: 0.12422784324735403\n"
     ]
    }
   ],
   "source": [
    "train(train_data, net, loss, trainer, CTX, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
