{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with GluonCV\n",
    "\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Install GluonCV through `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import gluoncv\n",
    "from gluoncv.utils import makedirs, download\n",
    "from gluoncv.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Pre-trained Models\n",
    "\n",
    "Let's load an image first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('https://www.catster.com/wp-content/uploads/2017/07/gray-and-white-cat-asleep-with-whiskers-out.jpg', path='./cat1.jpg')\n",
    "filename = 'cat1.jpg'\n",
    "img = mx.image.imread(filename)\n",
    "plt.imshow(img.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a good model, load pre-trained weights with `pretrained=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet152_v2'\n",
    "net = gluoncv.model_zoo.get_model(model_name, pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the image with the preset transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = gluoncv.data.transforms.presets.imagenet.transform_eval(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the transformed image look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.imshow(np.transpose(transformed_img[0].asnumpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation does the following two things:\n",
    "\n",
    "1. Crop the center square\n",
    "2. Normalizes the input image\n",
    "\n",
    "With this, we can predict with one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(transformed_img)\n",
    "prob = mx.nd.softmax(pred)[0].asnumpy()\n",
    "prob.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the top-5 predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = mx.nd.softmax(pred)[0].asnumpy()\n",
    "ind = mx.nd.topk(pred, k=5)[0].astype('int').asnumpy().tolist()\n",
    "print('The input picture is classified to be')\n",
    "for i in range(5):\n",
    "    print('- [%s], with probability %.3f.'%(net.classes[ind[i]], prob[ind[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the model gives the correct result. How about a smaller one?\n",
    "\n",
    "You only need to change the name of the model from the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MobileNet0.25'\n",
    "net = gluoncv.model_zoo.get_model(model_name, pretrained=True)\n",
    "pred = net(transformed_img)\n",
    "prob = mx.nd.softmax(pred)[0].asnumpy()\n",
    "ind = mx.nd.topk(pred, k=5)[0].astype('int').asnumpy().tolist()\n",
    "print('The input picture is classified to be')\n",
    "for i in range(5):\n",
    "    print('- [%s], with probability %.3f.'%(net.classes[ind[i]], prob[ind[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller model is not that confident, but still gives a good enough prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with your own data\n",
    "\n",
    "Now we are going to demonstrate how to transfer the knowledge from pre-trained model to your own domain.\n",
    "\n",
    "We use a sampled smaller dataset in this tutorial. Introduction to the entire dataset can be found at [this page](https://gluon-cv.mxnet.io/build/examples_classification/transfer_learning_minc.html#data-preparation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/minc-2500-tiny.zip'\n",
    "zip_file = download(file_url, path='./')\n",
    "with zipfile.ZipFile(zip_file, 'r') as zin:\n",
    "    zin.extractall(os.path.expanduser('./'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 23\n",
    "\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "per_device_batch_size = 1\n",
    "momentum = 0.9\n",
    "wd = 0.0001\n",
    "\n",
    "lr_factor = 0.75\n",
    "lr_steps = [10, 20, 30, np.inf]\n",
    "\n",
    "num_gpus = 1\n",
    "#num_workers = 8\n",
    "#ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "#batch_size = per_device_batch_size * max(num_gpus, 1)\n",
    "\n",
    "ctx = mx.gpu()\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, transformation, which is the preprocessing.\n",
    "We implement the same preprocessing function as ImageNet.\n",
    "\n",
    "Note: keep the transformation consistent with the original model training is important in transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    transforms.RandomColorJitter(brightness=jitter_param, contrast=jitter_param,\n",
    "                                 saturation=jitter_param),\n",
    "    transforms.RandomLighting(lighting_param),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256, keep_ratio=True),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data into train, validation, and test.\n",
    "\n",
    "For validation and test, we use the same transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './minc-2500-tiny'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(train_path).transform_first(transform_train),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(val_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(test_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is prepared. We define the model, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1024 -> 1000, linear)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'MobileNet1.0'\n",
    "finetune_net = get_model(model_name, pretrained=True)\n",
    "finetune_net.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(None -> 23, linear)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "finetune_net.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_net.output.initialize(init.Xavier(), ctx = ctx, force_reinit=True)\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "# Trainer, metric, loss\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                        'learning_rate': lr, 'momentum': momentum, 'wd': wd})\n",
    "metric = mx.metric.Accuracy()\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a function to measure the performance on validation and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = batch[0].as_in_context(ctx)\n",
    "        label = batch[1].as_in_context(ctx)\n",
    "        outputs = net(data)\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can start our training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train-acc: 0.348,  | Val-acc: 0.217 |\n",
      "[Epoch 1] Train-acc: 0.330,  | Val-acc: 0.174 |\n",
      "[Epoch 2] Train-acc: 0.409,  | Val-acc: 0.152 |\n",
      "[Epoch 3] Train-acc: 0.452,  | Val-acc: 0.174 |\n",
      "[Epoch 4] Train-acc: 0.409,  | Val-acc: 0.239 |\n",
      "[Finished] Test-acc: 0.217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset()\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = batch[0].as_in_context(ctx)\n",
    "        label = batch[1].as_in_context(ctx)\n",
    "        with ag.record():\n",
    "            outputs = finetune_net(data)\n",
    "            loss = L(outputs, label)\n",
    "        loss.backward()\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    _, train_acc = metric.get()\n",
    "\n",
    "    _, val_acc = test(finetune_net, val_data, ctx)\n",
    "\n",
    "    print('[Epoch %d] Train-acc: %.3f,  | Val-acc: %.3f |' %\n",
    "             (epoch, train_acc, val_acc))\n",
    "\n",
    "_, test_acc = test(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_net.save_parameters('tinynet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is a small example, it is basically how we train a model on much larger dataset.\n",
    "\n",
    "## Further resources\n",
    "\n",
    "On the GluonCV Classification Model Zoo page, we provide:\n",
    "\n",
    "- Training scripts for ImageNet and CIFAR10.\n",
    "- Training hyperparameters to reproduce.\n",
    "- Training Logs to compare speed and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
